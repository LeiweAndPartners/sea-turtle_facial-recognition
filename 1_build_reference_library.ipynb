{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd383243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Google Colab\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Install LightGlue and dependencies if on Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running on Google Colab - Installing dependencies...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"git+https://github.com/cvg/LightGlue.git\"], check=True)\n",
    "    subprocess.run([\"pip\", \"install\", \"opencv-python-headless\"], check=True)\n",
    "    print(\"Dependencies installed!\")\n",
    "else:\n",
    "    print(\"Running locally - assuming dependencies are installed via Poetry/Conda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# LightGlue imports\n",
    "from lightglue import SIFT\n",
    "from lightglue.utils import load_image\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ee7bf",
   "metadata": {},
   "source": [
    "## 1. Load Reference Images\n",
    "\n",
    "Loading all turtle images from the `data/initial_database` directory. Each image represents either the left or right side of a turtle's face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d22fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "data_dir = Path(\"data/initial_database\")\n",
    "if not data_dir.exists():\n",
    "    print(f\"Warning: {data_dir} not found. Creating directory structure...\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load all JPG images\n",
    "image_paths = list(data_dir.glob(\"*.jpg\")) + list(data_dir.glob(\"*.JPG\"))\n",
    "print(f\"Found {len(image_paths)} images:\")\n",
    "for path in sorted(image_paths):\n",
    "    print(f\"  - {path.name}\")\n",
    "\n",
    "# Dictionary to store images and tensors\n",
    "reference_images = {}\n",
    "reference_tensors = {}\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Load for display purposes\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is not None:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        reference_images[img_path.stem] = img_rgb\n",
    "        \n",
    "        # Load as tensor for LightGlue\n",
    "        try:\n",
    "            img_tensor = load_image(str(img_path)).to(device)\n",
    "            reference_tensors[img_path.stem] = img_tensor\n",
    "            print(f\"Loaded: {img_path.name} - Shape: {img_rgb.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load tensor for {img_path.name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Failed to load: {img_path.name}\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(reference_images)} reference images\")\n",
    "print(f\"Successfully loaded {len(reference_tensors)} reference tensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04498eeb",
   "metadata": {},
   "source": [
    "## 2. Display Reference Images\n",
    "\n",
    "Let's visualize all our reference turtle images to understand our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid display of all reference images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, image) in enumerate(sorted(reference_images.items())):\n",
    "    if idx < len(axes):\n",
    "        axes[idx].imshow(image)\n",
    "        axes[idx].set_title(name, fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for idx in range(len(reference_images), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Sea Turtle Reference Database\\n(5 Turtles √ó 2 Sides = 10 Images)', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db09e4",
   "metadata": {},
   "source": [
    "## 3. Extract SIFT Keypoints\n",
    "\n",
    "SIFT (Scale-Invariant Feature Transform) detects distinctive keypoints that are robust to scaling, rotation, and illumination changes - perfect for turtle facial recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LightGlue SIFT extractor\n",
    "extractor = SIFT(max_num_keypoints=2048).eval().to(device)\n",
    "\n",
    "# Dictionary to store keypoints and descriptors\n",
    "reference_library = {}\n",
    "\n",
    "print(\"Extracting SIFT keypoints using LightGlue...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, img_tensor in reference_tensors.items():\n",
    "    # Extract features using LightGlue SIFT\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = extractor({'image': img_tensor})\n",
    "    \n",
    "    extraction_time = time.time() - start_time\n",
    "    \n",
    "    if features['keypoints'] is not None and len(features['keypoints'][0]) > 0:\n",
    "        # Store features in LightGlue format\n",
    "        reference_library[name] = {\n",
    "            'keypoints': features['keypoints'].cpu(),\n",
    "            'descriptors': features['descriptors'].cpu(),\n",
    "            'image_shape': img_tensor.shape[-2:],  # (H, W)\n",
    "            'num_keypoints': len(features['keypoints'][0]),\n",
    "            'extraction_time': extraction_time\n",
    "        }\n",
    "        \n",
    "        print(f\"{name:20s} | {len(features['keypoints'][0]):4d} keypoints | {extraction_time:.3f}s\")\n",
    "    else:\n",
    "        print(f\"{name:20s} | Failed to extract keypoints!\")\n",
    "        reference_library[name] = None\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Successfully processed {len([k for k in reference_library.values() if k is not None])} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43cf922",
   "metadata": {},
   "source": [
    "## 4. Visualize SIFT Keypoints\n",
    "\n",
    "Let's examine the keypoints detected on each turtle image to understand what features SIFT is capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d61fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize keypoints for each turtle\n",
    "fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "def lightglue_to_opencv_keypoints(lg_keypoints):\n",
    "    \"\"\"Convert LightGlue keypoints to OpenCV format for visualization.\"\"\"\n",
    "    cv_keypoints = []\n",
    "    for kp in lg_keypoints[0]:  # Remove batch dimension\n",
    "        x, y = kp.cpu().numpy()\n",
    "        cv_kp = cv2.KeyPoint(x=float(x), y=float(y), size=20)\n",
    "        cv_keypoints.append(cv_kp)\n",
    "    return cv_keypoints\n",
    "\n",
    "for idx, (name, data) in enumerate(sorted(reference_library.items())):\n",
    "    if idx < len(axes) and data is not None:\n",
    "        # Convert LightGlue keypoints to OpenCV format for visualization\n",
    "        cv_keypoints = lightglue_to_opencv_keypoints(data['keypoints'])\n",
    "        \n",
    "        # Draw keypoints on the image\n",
    "        image = reference_images[name]\n",
    "        img_with_kp = cv2.drawKeypoints(\n",
    "            image, \n",
    "            cv_keypoints, \n",
    "            None, \n",
    "            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "        )\n",
    "        \n",
    "        axes[idx].imshow(img_with_kp)\n",
    "        axes[idx].set_title(f\"{name}\\n{data['num_keypoints']} keypoints\", \n",
    "                           fontsize=11, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(reference_library), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('SIFT Keypoints Detection Results\\n(Keypoints shown as circles with orientation)', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d157b000",
   "metadata": {},
   "source": [
    "## 5. Keypoint Statistics\n",
    "\n",
    "Let's analyze the distribution of keypoints across our turtle images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather statistics\n",
    "keypoint_counts = []\n",
    "turtle_names = []\n",
    "sides = []\n",
    "\n",
    "for name, data in reference_library.items():\n",
    "    if data is not None:\n",
    "        keypoint_counts.append(data['num_keypoints'])\n",
    "        # Parse turtle name and side\n",
    "        parts = name.split()\n",
    "        turtle_names.append(parts[0])\n",
    "        sides.append(parts[1] if len(parts) > 1 else 'Unknown')\n",
    "\n",
    "# Create statistics visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Keypoint count by turtle\n",
    "turtle_kp_data = {}\n",
    "for turtle, count in zip(turtle_names, keypoint_counts):\n",
    "    if turtle not in turtle_kp_data:\n",
    "        turtle_kp_data[turtle] = []\n",
    "    turtle_kp_data[turtle].append(count)\n",
    "\n",
    "turtles = list(turtle_kp_data.keys())\n",
    "avg_keypoints = [np.mean(turtle_kp_data[turtle]) for turtle in turtles]\n",
    "\n",
    "bars1 = ax1.bar(turtles, avg_keypoints, alpha=0.7, color=sns.color_palette(\"husl\", len(turtles)))\n",
    "ax1.set_title('Average Keypoints per Turtle', fontweight='bold')\n",
    "ax1.set_ylabel('Average Number of Keypoints')\n",
    "ax1.set_xlabel('Turtle Name')\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars1, avg_keypoints):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "             f'{value:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Distribution histogram\n",
    "ax2.hist(keypoint_counts, bins=8, alpha=0.7, edgecolor='black')\n",
    "ax2.set_title('Distribution of Keypoint Counts', fontweight='bold')\n",
    "ax2.set_xlabel('Number of Keypoints')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.axvline(np.mean(keypoint_counts), color='red', linestyle='--', \n",
    "           label=f'Mean: {np.mean(keypoint_counts):.0f}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nKeypoint Extraction Summary:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total Images Processed: {len([d for d in reference_library.values() if d is not None])}\")\n",
    "print(f\"Average Keypoints per Image: {np.mean(keypoint_counts):.1f}\")\n",
    "print(f\"Standard Deviation: {np.std(keypoint_counts):.1f}\")\n",
    "print(f\"Min Keypoints: {min(keypoint_counts)}\")\n",
    "print(f\"Max Keypoints: {max(keypoint_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffcab9",
   "metadata": {},
   "source": [
    "## 6. Save Reference Library\n",
    "\n",
    "Now we'll save the reference library to disk so it can be loaded quickly by the inference notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for serialization - LightGlue tensors are already serializable\n",
    "serializable_library = {}\n",
    "\n",
    "for name, data in reference_library.items():\n",
    "    if data is not None:\n",
    "        # LightGlue features are already in tensor format and can be saved directly\n",
    "        serializable_library[name] = {\n",
    "            'keypoints': data['keypoints'],  # Already CPU tensors\n",
    "            'descriptors': data['descriptors'],  # Already CPU tensors\n",
    "            'image_shape': data['image_shape'],\n",
    "            'num_keypoints': data['num_keypoints'],\n",
    "            'extraction_time': data['extraction_time']\n",
    "        }\n",
    "\n",
    "# Save to pickle file\n",
    "library_path = \"reference_library.pkl\"\n",
    "try:\n",
    "    with open(library_path, 'wb') as f:\n",
    "        pickle.dump(serializable_library, f)\n",
    "    \n",
    "    # Verify the save was successful\n",
    "    file_size = os.path.getsize(library_path) / 1024  # KB\n",
    "    print(f\"‚úÖ Reference library saved successfully!\")\n",
    "    print(f\"   üìÅ File: {library_path}\")\n",
    "    print(f\"   üìä Size: {file_size:.1f} KB\")\n",
    "    print(f\"   üê¢ Contains: {len(serializable_library)} turtle images\")\n",
    "    \n",
    "    # Test loading the file\n",
    "    with open(library_path, 'rb') as f:\n",
    "        test_load = pickle.load(f)\n",
    "    print(f\"   ‚úÖ File integrity verified!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving reference library: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72ea1b",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "The reference library has been successfully created! Here's what we accomplished:\n",
    "\n",
    "1. **Loaded 10 turtle images** from 5 different turtles (left and right sides)\n",
    "2. **Extracted SIFT keypoints** using OpenCV's robust feature detector\n",
    "3. **Visualized keypoints** to understand feature distribution\n",
    "4. **Analyzed statistics** across turtle images\n",
    "5. **Saved reference library** for use in turtle identification\n",
    "\n",
    "### Next Steps:\n",
    "- Use the inference notebook (`2_turtle_identification.ipynb`) to identify new turtle images\n",
    "- The saved `reference_library.pkl` contains all keypoint data needed for matching\n",
    "\n",
    "### Key Insights:\n",
    "- Each turtle image contains hundreds of distinctive keypoints\n",
    "- SIFT successfully captures facial features like eye patterns, shell markings, and texture\n",
    "- The library is now ready for real-time turtle identification!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
